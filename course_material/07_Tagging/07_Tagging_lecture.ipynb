{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP tasks\n",
    "\n",
    "* Written language is a sequence of characters\n",
    "* We will use text as list of words\n",
    "  * tokenization\n",
    "\n",
    "<!-- From the data point of view, written language is a sequence of characters. To introduce one of the earliest and most fundamental task in NLP, we consider the text as the list of words. Breaking the text into words is not always that easy as in the example, that is called __tokenization__. We deal with tokenized texts for now. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"The cat sat on the mat\"\n",
    "words = x.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The computer does not know anything about words or any human language\n",
    "  * we consider the words as abstract labels\n",
    "* Usually we put the words into a vocabulary and assign an integer ID to all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {w:i for i, w in enumerate(set(x.split()))}\n",
    "print(vocabulary)\n",
    "print(\"------------------\")\n",
    "print(words)\n",
    "print([vocabulary[w] for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, this is what we have to compute with, but later you will learn more about representing words (other than meaningless IDs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS\n",
    "__Part-of-speech__ tag is a property of words. More precisely, we put words into categories according what role they play in a given sentence.\n",
    "\n",
    "#### Example\n",
    "\n",
    "| The|dog|saw| a|cat|.|\n",
    "|----|---|---|--|---|---|\n",
    "| determiner|noun|verb| determiner|noun|punctuation|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The categorization is aimed to label interchangeable words with the same label. For example __cat__ could be replaced with __dog__, __boat__ or any other nouns, but not with a verb.\n",
    "-->\n",
    "* Interchangeable words should end up in the same category.\n",
    "  * The category is the __pos tag__\n",
    "* The correct tag depends on the context, not only the word itself.\n",
    "\n",
    "|You|talk|the|talk|but|do|you|walk|the|walk|?|\n",
    "|---|----|---|----|---|--|---|----|---|----|-|\n",
    "|pronoun|verb|determiner|noun|conjunction|verb|pronoun|verb|determiner|noun|punctuation|\n",
    "\n",
    "* One can change the verbs to __give__ which is an other verb, but not the nouns.\n",
    "* You cannot put any verb in place of _\"give\"_ because the sentence loses its meaning.\n",
    "  * POS tag only tells the grammatical role: what words can take place without compromising the grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging\n",
    "... is a task to label every word in a given text with the appropriate POS tags. An algorithm for that will be our very first NLP task!\n",
    "\n",
    "### Tagsets\n",
    "* The tags themselves are the result of linguistic/NLP consensus\n",
    "  * there are several conventions for them. \n",
    "* From computational point of view, there is no definition for POS tags\n",
    "  * Benchmark datasets are the definition (gold standard) of what the correct tags are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Universal Dependencies](https://github.com/UniversalDependencies/UD_English) using [Universal POS tags](http://universaldependencies.org/u/pos/all.html):\n",
    "\n",
    "|This|killing|of|a|respected|cleric|will|be|causing|us|trouble|for|years|to|come|.|\n",
    "|---|----|---|---|---|----|---|---|----|----|----|---|----|----|----|-----|\n",
    "|DET|NOUN|ADP|DET|ADJ|NOUN|AUX|AUX|VERB|PRON|NOUN|ADP|NOUN|PART|VERB|PUNCT|\n",
    "\n",
    "Or a [hungarian one](https://github.com/UniversalDependencies/UD_Hungarian)\n",
    "\n",
    "|A|gazdaság|ilyen|mértékű|fejlődését|több|folyamat|gerjeszti|.|\n",
    "|-|--------|-----|-------|----------|----|--------|---------|-|\n",
    "|DET|NOUN|DET|ADJ|NOUN|DET|NOUN|VERB|PUNCT|\n",
    "\n",
    "The Universal tagset is language independent, except some language specific features. For example the words _\"cleric\"_ and _\"gazdaság\"_ are both NOUNs. In English  _\"a\"_ and _\"the\"_ are determinants, in Hungarian _\"a\"_ and _\"az\"_ have similar grammatical functions.\n",
    "\n",
    "From [UMBC webbase](http://ebiquity.umbc.edu/resource/html/id/351) corpus using [Penn Treebank tagset](https://ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html):\n",
    "\n",
    "|Well| ,| let| me| just| say| there| is| n't| too| much| I| can| tell| you| right| at| the| moment| .|\n",
    "|---|--|---|----|---|----|---|----|---|---|---|----|---|---|----|---|---|---|---|-|\n",
    "|RB |, |VB |PRP |RB |VBP |EX |VBZ |RB |RB |JJ |PRP |MD |VB |PRP |RB |IN |DT |NN |.|\n",
    "\n",
    "The latter is just for English, note the EX (existential _there_) tag and the token _\"n't\"_ after _\"is\"_ with tag RB.\n",
    "\n",
    "These are also tokenized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging in general\n",
    "<!-- In general, a tagging task requires a labeled dataset: a list of symbols with a list of corresponding target symbols.\n",
    "\n",
    "The \"sentence\" is a list of source symbols (tokens or words), and the target symbols are from a (more-or-less) well defined set.\n",
    "-->\n",
    "\n",
    "|$word_1$| $word_2$| $word_3$| $\\ldots$|\n",
    "|---|--|---|----|\n",
    "|$tag_1$ |$tag_2$  |$tag_3$  |$\\ldots$ |\n",
    "\n",
    "> __Definition__ (Token)\n",
    "> _The atoms of interest, in our case the words of a text._\n",
    "\n",
    "> __Definition__ (Corpus)\n",
    "> _A list of tokens_\n",
    "\n",
    "> __Definition__ ([Tokenization](https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html))\n",
    "> _The task of splitting a list of characters (raw text) into tokens._\n",
    "\n",
    "> __Definition__ (Tagset)\n",
    "> _A finite (usually small) set of symbols, which are linguistically defined properties of tokens._\n",
    "\n",
    "> __Definition__ (Labeled corpus)\n",
    "> _A List of (token, tag) pairs, where the tags are from a given tagset._\n",
    "\n",
    "> __Definition__ (Tagging)\n",
    "> _Take a given (unlabeled) corpus and tagset. The_ tagging _is the task of assigning the tags to tokens._\n",
    "\n",
    "Sometimes a corpus is split at sentence boundaries, which means that sentences can be processed separately. \n",
    "Otherwise, a sentence boundary is just a special punctuation or end-of-sentence symbol.\n",
    "\n",
    "There are cases, where the POS tag of a word cannot be deduced within a sentence, only in context of other sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminoligy\n",
    "If the tags would be algorithmically well-defined, then implementing that definition would result a 100% correct tagger without any further ado. However, this is not the case with natural language.\n",
    "\n",
    "There are __rule based__ approaches, where linguistic or grammatical rules are implemented, but every language has exceptions.\n",
    "\n",
    "If one does not use such rules, only the previously correctly labeled data, that is the __statistical__ approach, because the resulted algorithm is conditioned to the previously seen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the statistical approach: <!-- , we split the data into two parts. One for training, this is at the disposal of our algorithm.\n",
    "The other part of the split is for testing. The correct labels are stripped off of the test set and are compared to the output of the algorithm.-->\n",
    "\n",
    "> __Training__\n",
    "> _Setting up the algorithm for a given task. This uses a previously correctly labeled data._\n",
    "\n",
    "> __Train set__\n",
    "> _A previously correctly labeled data. Your algorithm can use any information in the training set._\n",
    "\n",
    "> __Prediction/inference__\n",
    "> _The labeling of an unlabeled data with your algorithm. This is the main task itself._\n",
    "\n",
    "> __Test/unseen data__\n",
    "> _A previously correctly labeled data, but its labels are not communicated with the algorithm._\n",
    "\n",
    "> __Evaluation__\n",
    "> Comparing the output of the predicted and correct labels (it is done on the test data).\n",
    "\n",
    "> __Annotating__\n",
    "> _The human labor of making the gold dataset. Manually processing sentences and label them correctly._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Gold data__\n",
    "> _Annotated corpus, usually annotated with serious efforts and for a specific task._\n",
    "\n",
    "> __Silver data__\n",
    "> _Not that good quality or automatically labeled data._\n",
    "\n",
    "> __Test on train__\n",
    "> _If you evaluate on the same data as you trained on. Every sound algorithm is expected to perform well (if not perfectly) on training data. It is not a decent test of your algorithm._\n",
    "\n",
    "<!-- Sometimes we call the correctly labeled dataset __gold data__, usually annotated with serious efforts. If a given data is not perfectly labeled, or come from unknown origin, or the labels themselves are questionable, them we can talk about __silver data__. Silver is not always correct, but without any better at hand, they are used as training data. Sometimes silver data is acquired with automated or semi-automated techniques rather than human annotation.\n",
    "\n",
    "It is worth mentioning that one can evaluate a model on the training data, but it does not tell much about the correctness of the algorithm. If you train an algorithm and use the training set in the prediction, thats called __test on train__.  Every sound algorithm is expected to perform well (if not perfectly) on training data, since that data was available during the design/making of the algorithm. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tagging tasks\n",
    "Beside POS tagging, there are several other tasks.\n",
    "\n",
    "#### NER\n",
    "Named entity recognition.\n",
    "\n",
    "> <u>Uber</u> isn't pulling out of <u>Quebec</u> just yet.<br>\n",
    "> <u>Bill Gates</u> buys <u>Apple</u>. <u>DJIA</u> crashing!\n",
    "\n",
    "* Mark names of things in text\n",
    "* Find whether a word or sequence of words is a thing or not, mostly persons, places, companies\n",
    "* Grammatically they are replaceable with _\"someone\"_ or _\"some remarkable place\"_ or _\"some legal entity\"_\n",
    "* From the human point of view, they carry a lots of valuable informations because of their very being."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example the target labels are just $\\{0,1\\}$ marking whether it is a named entity or not. There are more detailed NER tagsets which tells you what that entity is (plus one tag for _\"not a named entity\"_).\n",
    "\n",
    "|tagset|# of tags| language independent | |\n",
    "|:---|:--|:--:|:--|\n",
    "|CoNLL| 4  |yes|Person, Location, Organization, Misc|\n",
    "|Penn Treebank|22|no|Animal, Cardinal, Date, Disease,...|\n",
    " \n",
    "Identifying these parts of the text helps understanding what real word entities play role in a given sentence, hence retrieving information from the text.\n",
    "\n",
    "It is a different task, to match various forms of the same entity, like: _USA_, _United States of America_, _The States_, _'merica_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NP-chunking\n",
    "| He | reckons |the current account deficit| will narrow| to |only £1.8 billion |in|September|.|\n",
    "|:--:|:-------:|:-------------------------:|:----------:|:--:|:----------------:|:-:|:------:|:-:|\n",
    "|NP  |         |NP                         |            |    |    NP            |   |      NP|  |\n",
    "\n",
    "Finds __noun-phrases__ which correspond to a single agent in the sentence.\n",
    "\n",
    "The one who (or what):\n",
    "* does something\n",
    "* the action is performed on\n",
    "* involved in some action\n",
    "\n",
    "It is often called __shallow parsing__ because it finds some components of the sentence but not the whole structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive ways\n",
    "Here we discuss some naive approaches and common mistakes.\n",
    "\n",
    "##### The tag (label) of a word is not a function of the word itself.\n",
    "* It depends on the context, the surrounding words.\n",
    "* Most of the words can have several part-of-speech tags.\n",
    "* In English noun-verbs are common: _work_, _talk_, _walk_.\n",
    "\n",
    "##### Names entities are not always proper nouns\n",
    "Neither start with capital letters.\n",
    "\n",
    "Counter examples:\n",
    "* the States\n",
    "* von Neumann\n",
    "\n",
    "The begging of the sentence is capital regardless of the named entities.\n",
    "\n",
    "##### There is no comprehensive list of all named entities\n",
    "* Let's suppose that one wants to collect every famous person, geographic place, company, trademark and title (real and fictional ever) in a list.\n",
    "* That list will never be comprehensive, since a well known thing can be mentioned in an unusual or abbreviated form.\n",
    "* And the list would became obsolete very soon, since new movies, books, famous person and firms are born."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stanford CoreNLP\n",
    "http://nlp.stanford.edu:8080/corenlp/\n",
    "\n",
    "This software performs various NLP tasks from POS tagging to grammatical analysis.\n",
    "It is written in Java, you can use it with API, GUI, command line, web service. It has a good performance and speed and uses much more sophisticated methods than what we will learn.\n",
    "\n",
    "#### Examples\n",
    "> The temperature is 26.1 degree Celsius outside. the Sun is shining.<br>\n",
    "> 220 Volts is considered a high voltage.\n",
    "\n",
    "Supports several major languages (other than English): Chinese, Spanish, Arabic, French and German."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some obstacles\n",
    "### Training data\n",
    "* Bad quality or insufficient training data.\n",
    "* Luckily, the aforementioned tasks have well established and gold standard databases.\n",
    "* Also, every dataset have some mistakes in it.\n",
    "\n",
    "There is a trade-off between the quality and quantity. Human annotated data are of higher quality but fewer in quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "* Without proper evaluation, any model is questionable.<!-- Without test data, you cannot tell how good your model was.-->\n",
    "* Given a certain amount of gold data, you have to decide how to cut it into train and testing.\n",
    "* Insufficient testing data can result an unreliable algorithm.\n",
    "\n",
    "\n",
    "* You can see the output of your algorithm for yourself, but lacks statistical perspective\n",
    "* Getting 10 of your favorite sentences right doesn't mean that your algorithm rocks!\n",
    "* This is called __testing by glance__, you are advised to avoid it.\n",
    "<!-- Without any test data, you can compete your algorithm against humans, or see it for yourself. This kind of manual test is expensive in human time and lacks statistical perspective if you don't use enough annotators. Getting 10 of your favorite sentences right doesn't mean that your algorithm rocks!\n",
    "-->\n",
    "\n",
    "This is a serious problem in machine translation, where you don't even have a correct automated testing.\n",
    "<!-- A sentence can have several equally good translations, so if your algorithm does not give you the desired result, that doesn't mean that the translation was wrong. It's difficult to even compare sentences and tell that they mean a similar thing, if they have a different wording. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold is not gold\n",
    "* No matter what NLP task you take, a 100% correct algorithm cannot be reached.\n",
    "* There are always exceptions and never-seen structures, words.\n",
    "* Even gold data can be contradictory, or even undefined.\n",
    "\n",
    "> We are doing it by the Book!\n",
    "\n",
    "* Is _\"the Book\"_ a named entity or just an expression of doing it right?\n",
    "* It can depend on the context, or who you talk to.\n",
    "\n",
    "### Linguistic change\n",
    "Healthy languages changes over time and can have new words, expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "The above tasks are a type of a broader class of tasks. Namely, take any dataset which is a set of __training examples__ and their corresponding __labels__.\n",
    "\n",
    "The labels are usually from a small set.\n",
    "\n",
    "* German nouns and their article (der, die, das)\n",
    "* pairs of images and what is seen on them\n",
    "* movies and their IMDB ratings\n",
    "\n",
    "|data|label|\n",
    "|---|-----|\n",
    "|$x_1$|$y_1$|\n",
    "|$x_2$|$y_2$|\n",
    "|$\\vdots$|$\\vdots$|\n",
    "|$x_{n+1}$|  |\n",
    "|$x_{n+2}$|  |\n",
    "|$\\vdots$ |  |\n",
    "\n",
    "The task is similar to before: given the training set, try to predict the labels of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential data\n",
    "* In the case of text, sequential information is very relevant in the data.\n",
    "* We usually need the order of the data as input information.\n",
    "* Also one can take a window around the word-of-interest and think of it as unordered data.\n",
    "\n",
    "|$x_1$|$x_2$|$x_3$|$x_4$|$x_5$|$\\ldots$|\n",
    "|-----|-----|-----|-----|-----|-----|\n",
    "|$l_1$|$l_2$|$l_3$|$l_4$|$l_5$|$\\ldots$|\n",
    "\n",
    "| data    | label |\n",
    "|---------|-------|\n",
    "|$(\\ , \\ , x_1, x_2, x_3)$|$l_1$|\n",
    "|$(\\ , x_1, x_2, x_3, x_4)$|$l_2$|\n",
    "|$(x_1, x_2, x_3, x_4, x_5)$|$l_3$|\n",
    "|$(x_2, x_3, x_4, x_5, x_6)$|$l_4$|\n",
    "|$\\vdots$| $ \\vdots$|\n",
    "\n",
    "* With this rearranging, one can transform any NLP task into a supervised learning task.\n",
    "* The problem is when 5, 10 or 20 width window is not enough, because there may be __long distance relations__ between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM\n",
    "### A simple POS tagger\n",
    "* Let's write a very simple tagger.\n",
    "* Given the corpus, establish a vocabulary $V$ with every word in it\n",
    "  * and the set of labels $L$\n",
    "* The corpus is a list of pairs in $V\\times L$.\n",
    "* Usually $|V|\\approx 10^5, 10^6$ and $|L|$ is never more than $100$\n",
    "\n",
    "Lets build a lookup table which assigns what POS tag can follow a certain list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "corpus=list(zip([\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \".\"],\n",
    "                [\"DET\", \"ADJ\", \"ADJ\", \"NOUN\", \"VERB\", \"ADP\", \"DET\", \"ADJ\", \"NOUN\", \"PUNCT\"]))\n",
    "print(corpus)\n",
    "n=3\n",
    "pos_lookup=OrderedDict([(tuple(corpus[j][0] for j in range(max(i-2,0),i+1)), corpus[i][1]) for i in range(len(corpus))])\n",
    "print()\n",
    "pos_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this table, you can determine what is the POS tag of a given word if you have ever seen that word and its preceding words in the corpus. We will call this a __Markov model__.\n",
    "\n",
    "The assumption of the Markov model is that if you take a long enough sequence of words, then they determine, without doubt, the POS tag of the last word. For example:\n",
    "\n",
    "> work -> it can be noun or verb<br>\n",
    "> my <u>work</u> -> noun<br>\n",
    "> I <u>work</u> -> verb<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the words after the word-of-interest.\n",
    "Also it may happen that the window around the word is not big enough and the same word with the same surrounding words can have several possible POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lookup2 = OrderedDict()\n",
    "for i in range(len(corpus)):\n",
    "    words_before = tuple(corpus[j][0] for j in range(max(i-2,0),i))\n",
    "    word_of_interest = corpus[i][0]\n",
    "    words_after = tuple(corpus[j][0] for j in range(i+1,min(i+3, len(corpus))))\n",
    "    if (words_before, word_of_interest, words_after) in pos_lookup2:\n",
    "        pos_lookup2[(words_before, word_of_interest, words_after)] |= {corpus[i][1]}\n",
    "    else:\n",
    "        pos_lookup2[(words_before, word_of_interest, words_after)] = {corpus[i][1]}\n",
    "print()\n",
    "dict(pos_lookup2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can use the words after the target word\n",
    "  * but not the gold tags, not even before the target word.\n",
    "* Temporarily, you can use previously predicted labels as if they were correct\n",
    "  * but in the end, test prediction cannot use any gold labels.\n",
    "\n",
    "The algorithm is as follows:\n",
    "* look up a given word with the surrounding words.\n",
    "* If the sequence is in the table, then use the corresponding tag, or any of the tags.\n",
    "* If not, then make a guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "* If there is a word in the test set, but not in the train set\n",
    "  * This is called __out-of-vocabulary__ or __OOV__.\n",
    "\n",
    "* If the target word is in the test set, but not between a particular set of words\n",
    "  * This is called the __data sparsity__.\n",
    "\n",
    "For example if one takes the word _\"the\"_, then it is most certainly a determinant. However take the following segment:\n",
    "\n",
    "> ... Steve Jobs met the Dalai Lama ...\n",
    "\n",
    "The word _\"the\"_ is still unknown if there was no Dalai, Lama, Steve or Jobs mentioned in the training set.\n",
    "\n",
    "* One may require hundreds of millions of sentences to encounter Steve Jobs and the Dalai Lama in the same sentence.\n",
    "* Or even worse: no English text ever written in the human history contains those four words in the same sentence (there is one know).\n",
    "\n",
    "These problems are not independent and they lead to much greater problems in NLP. One cannot solve this problem, only avoid it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model\n",
    "\n",
    "* In the following model we take only the preceding words (like in the Markov model)\n",
    "* We call the POS tag a __hidden parameter__.\n",
    "* We suppose that there must be some underlying POS tag which is not seen directly, but governs the words in the text.\n",
    "\n",
    "* Think of the pos tags as the grammatical backbone of the sentences.\n",
    "\n",
    "|PRON|VERB |PRON|PREP|NOUN|PUNCT|\n",
    "|---|-----|-----|----|--------|--|\n",
    "| I | saw | you | in | school | .|\n",
    "|You| saw |  me | in | school | .|\n",
    "|You| met |  me | in | school | .|\n",
    "|You| met |  me | in | work | .|\n",
    "|We| met |him | at | work | .|\n",
    "\n",
    "We will think of a sentence as the sequence of POS tags, for which the actual choice of words is rather arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model\n",
    "* We suppose that there is some mechanism which puts the pos tags after each other\n",
    "* For a given POS tag, the actual word is just random\n",
    "  * according to some distribution\n",
    "* We are looking for a sequence of tags that can generate the given words with the highest probability.\n",
    "* More precisely, have a probabilistic model ($n$ is the length of the sentence).\n",
    "$$\n",
    "\\mathbb{P}(w_1, w_2, \\ldots w_n, l_1, l_2 \\ldots l_n)\n",
    "$$\n",
    "For example\n",
    "$$\\mathbb{P}(\\text{the}, \\text{dog}, \\text{saw}, \\text{the}, \\text{cat},\n",
    "\\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{DET}, \\text{NOUN})$$\n",
    "* Look for the best explaining tag sequence:\n",
    "$$\n",
    "{\\arg\\max}_{l_i\\in L}\\mathbb{P}(w_1, w_2, \\ldots w_n \\ | \\ l_1, l_2 \\ldots l_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general, this would require $O(|L|^n)$ complexity.\n",
    "* In the practical model we use some restrictions\n",
    "* Use a given window to the past, the window size is a model parameter.\n",
    "\n",
    "| I | saw | you | in | school | .|\n",
    "|---|:-----|-----|----:|--------|--|\n",
    "|DET|VERB |PRON|PREP|NOUN|PUNCT|\n",
    "|   |     |    | $w_i$ |||\n",
    "|   |$w_{i-2}$|$w_{i-1}$|$w_i$|||\n",
    "|   | [  |window|  ] ||\n",
    "\n",
    "* And also make the assumption that the probability of a sequence is:\n",
    "$$\n",
    "\\mathbb{P}(w_1, w_2, \\ldots w_n \\ | \\ l_1, l_2 \\ldots l_n) =\n",
    "    \\prod_{i=1}^n\\mathbb{P}(l_i \\ |\\ l_{i-k+1},l_{i-k+2}\\ldots l_{i-1})\\cdot\\mathbb{P}(w_i \\ | \\ l_i)\n",
    "$$\n",
    "\n",
    "* The term $\\mathbb{P}(l_i \\ |\\ l_{i-k+1},l_{i-k+2}\\ldots l_{i-1})$ is a Markovian probability: the probability of tag $l_i$, given the previous $k-1$ tags.\n",
    "* The terms $\\mathbb{P}(w_i|l_i)$ are __emission probabilities__: the probability of a word given its POS tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation from the corpus\n",
    "$$\\mathbb{P}(l_n|l_1,l_2\\ldots l_{n-1})\\approx \\frac{\\#\\{l_1,l_2\\ldots l_{n-1},l_n\\}}{\\#\\{l_1,l_2\\ldots l_{n-1}\\}}$$\n",
    "If the index not positive then we simply omit it:\n",
    "$$\n",
    "\\mathbb{P}(l_2|l_{-1},l_0, l_1) \\approx \\frac{\\#\\{l_1,l_2\\}}{\\#\\{l_1\\}} \\text{ and } \n",
    "\\mathbb{P}(l_1|l_{-1},l_0) \\approx \\frac{\\#\\{l_1\\}}{\\text{# of words}}\n",
    "$$\n",
    "\n",
    "$$ \\mathbb{P}(w_i|l_i) \\approx \\frac{\\#\\{\\text{word }w_i \\text{ with the tag }l_i\\}}{\\#\\{l_i\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above formulas do not suffer that much data sparsity.\n",
    "* Tagset is way smaller than the vocabulary, so the occurrences of tag-sequences are not that sparse.\n",
    "* The possible tags of a given words is saturated\n",
    "\n",
    "<!-- For example if you see the word _\"dog\"_ many times in the corpus, and never with the POS tag _DET_ then you can be pretty sure that it will never have that tag. -->\n",
    "\n",
    "* After we collected the estimations of the probabilities (training)\n",
    "* we need an algorithm to find the argmax (given a sequence of words).\n",
    "  * this is the inference/prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi algorithm\n",
    "We detail the case of tri-grams, $k=3$. Let $w_1, w_2, \\ldots w_n$ be a sentence and we are looking for the sequence of corresponding tags.\n",
    "\n",
    "Let $$\\pi(n, u, v) = \\max_{l_1, l_2 \\ldots l_{n-2}\\in L \\ , \\ l_{n-1} = u, l_n = v} \\mathbb{P}(w_1, w_2, \\ldots w_n \\left| \\ l_1, l_2 \\ldots l_n\\right.)$$\n",
    "\n",
    "The possibility of the most possible tag-sequence of length $n$ ending with $u$ and $v$ with token-sequence $w_1, w_2, \\ldots w_n$.\n",
    "\n",
    "Note that the function $\\pi$ satisfies the following property: every head sequences of an optimal tag-sequence should be optimal too.\n",
    "\n",
    "One can use dynamic programming to compute $\\pi(n, u, v)$ and backtracking to get the corresponding tag-sequence.\n",
    "From that, the final two tags ($u$ and $v$) follow easily.\n",
    "\n",
    "> set $\\pi(0, u, v) = 1, \\forall u, v\\in L$ <br>\n",
    "> begin for $k = 1\\ldots n$<br>\n",
    ">   $\\quad$  begin for $u, v \\in L$<br>\n",
    "> $\\quad \\quad \\pi(k,u,v) = \\max_{w\\in L} \\pi(k−1,w,u)\\cdot \\mathbb{P}(v \\ | \\ w,u)\\cdot \\mathbb{P}(w_k \\ | \\ v) $<br>\n",
    "> $\\quad$end for<br>\n",
    "> end for<br>\n",
    "> return $\\max_{u,v\\in L} \\pi(n,u,v)$\n",
    "\n",
    "The complexity is $O(n\\cdot |L|^k)$, in the example $k=3$.\n",
    "\n",
    "See more: http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation\n",
    "Lets suppose that one has a tagger and performed the tagging on the test set.\n",
    "\n",
    "|token|$w_1$|$w_2$|$\\ldots$|\n",
    "|:--|-----|-----|--------|\n",
    "|gold labels|$l_1$|$l_2$|$\\ldots$|\n",
    "|predicted labels|$p_1$|$p_2$|$\\ldots$|\n",
    "\n",
    "* The predicted and gold labels are compared to each other.\n",
    "* The performance of a tagger can be measured several ways:\n",
    "  * per-token accuracy:\n",
    "$$\\frac{\\# \\text{ correct labels}}{\\# \\text{ words}}$$\n",
    "  * per-sentence accuracy:\n",
    "$$\\frac{\\# \\text{ sentences with all correct labels}}{\\# \\text{ sentences}}$$\n",
    "  * unknown word accuracy:\n",
    "$$\\frac{\\# \\text{ correct labels of OOV words}}{\\# \\text{ OOV words}}$$\n",
    "\n",
    "* OOV is out-of-vocabulary, words that were seen in test time, but not in training time.\n",
    "* For the simple HMM model, we cannot deal with OOVs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification\n",
    "* If a tagset consists only two labels, then a more detailed measurement is possible.\n",
    "* At every token one can have either of the following 4 possibilities.\n",
    "\n",
    "| predicted\\gold | 0 | 1 |\n",
    "|-------:|----|---|\n",
    "| 0 | TN | FN |\n",
    "| 1 | FP | TP  |\n",
    "\n",
    "* TN: true negative, correct rejection, _\"shouldn't and didn't\"_\n",
    "* FN: false negative, miss, _\"should but didn't\"_\n",
    "* FP: false positive, false alarm, _\"shouldn't but did\"_\n",
    "* TP: true positive hit, _\"should and did\"_\n",
    "\n",
    "* And we can measure the following quantities:\n",
    "  * Precision: $\\frac{TP}{TP+FP}$\n",
    "  * Accuracy: $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "  * Recall: $\\frac{TP}{TP+FN}$\n",
    "  * F1 score (F-measure): harmonic mean of precision and recall\n",
    "$$ \\frac{2\\cdot \\text{Precision}\\cdot \\text{Recall}}{\\text{Precision} +\\text{Recall}}  = \\frac{2\\cdot TP}{2\\cdot TP + FN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Explanation\n",
    "* For example if an algorithm produces a single $1$ and all other tags are $0$, but that $1$ happens to be right\n",
    "  * then the precision is $100\\%$, but the recall is low.\n",
    "* If an algorithm produces all $1$s and one correct $0$\n",
    "  * then the recall is high and the precision is low.\n",
    "\n",
    "* F1 score takes both precision and accuracy into account.\n",
    "\n",
    "* Note that in the NER example it is a bit special, since a named entity can have several words and this is not a hit: _\"<u>Bill</u> Gates.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
