{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for mathematics, science and engineering\n",
    "https://scipy.org/\n",
    "\n",
    "## Scipy\n",
    "(pronounced \"Sigh Pie\")\n",
    "\n",
    "Higher level algorithms on top of `numpy`\n",
    "\n",
    "* numerical integration\n",
    "* optimization\n",
    "* interpolation\n",
    "* Signal Processing\n",
    "* Linear Algebra\n",
    "  * with sparse matrices\n",
    "* statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, scipy\n",
    "import scipy.linalg\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print('Target names:', iris.target_names)\n",
    "print('Features:', iris.feature_names)\n",
    "print(iris.data)\n",
    "\n",
    "first = iris.data[iris.target == 0]\n",
    "second = iris.data[iris.target == 1]\n",
    "third = iris.data[iris.target == 2]\n",
    "print(len(first), len(second), len(third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first average:\", first.mean(axis=0))\n",
    "print(\"second average:\", second.mean(axis=0))\n",
    "print(\"third average:\", third.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sepal width and length: \", scipy.stats.pearsonr(iris.data[:, 0], iris.data[:, 1])[0])\n",
    "print(\"petal width and length: \", scipy.stats.pearsonr(iris.data[:, 2], iris.data[:, 3])[0])\n",
    "print(\"\")\n",
    "print(\"sepal width and length for first class: \", scipy.stats.pearsonr(first[:, 0], first[:, 1])[0])\n",
    "print(\"sepal width and length for second class: \", scipy.stats.pearsonr(second[:, 0], second[:, 1])[0])\n",
    "print(\"sepal width and length for third class: \", scipy.stats.pearsonr(third[:, 0], third[:, 1])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A = 0.5*(numpy.diag(numpy.ones(7), k=1) - numpy.diag(numpy.ones(7), k=-1))\n",
    "b = numpy.ones(len(A))\n",
    "\n",
    "print('[A|b]:\\n{}'.format(numpy.concatenate((A, b.reshape(-1,1)), axis=1)))\n",
    "\n",
    "x = scipy.linalg.solve(A, b)### Sparse linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = scipy.sparse.diags([-0.5*numpy.ones(7), 0.5*numpy.ones(7)], [-1,1])\n",
    "bs = numpy.ones(8)\n",
    "\n",
    "print('[As|bs]:\\n{}'.format(numpy.concatenate((As.toarray(), bs.reshape(-1,1)), axis=1)))\n",
    "\n",
    "xs = scipy.sparse.linalg.spsolve(As.tocsr(), bs)\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-term matrix decomposition\n",
    "\n",
    "__Download [the file](http://sandbox.hlt.bme.hu/~gaebor/ea_anyag/python_nlp/movies.txt) and put it in the same folder, as your notebook!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_descriptions = {}\n",
    "vocab = {}\n",
    "with open(\"movies.txt\", \"rb\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        title, description = line.strip().split(b'\\t')\n",
    "        movie_descriptions[title] = description.split(b' ')\n",
    "        for word in set(movie_descriptions[title]):\n",
    "            if word not in vocab:\n",
    "                new_id = len(vocab)\n",
    "                vocab[word] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))\n",
    "print(b\" \".join(movie_descriptions[b\"The Matrix\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_id = {k: i for i, k in enumerate(movie_descriptions.keys())}\n",
    "id_to_movie = {i: k for k, i in movie_to_id.items()}\n",
    "id_to_word = {i: w for w, i in vocab.items()}\n",
    "print(\"The Matrix:\", movie_to_id[b\"The Matrix\"])\n",
    "print(\"0th movie:\", id_to_movie[0])\n",
    "print(len(movie_to_id)-1, \"th movie:\", id_to_movie[len(movie_to_id)-1])\n",
    "print(\"word id of dog:\", vocab[b\"dog\"])\n",
    "print(\"0th word:\", id_to_word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "i = []\n",
    "j = []\n",
    "k = []\n",
    "\n",
    "for title, description in movie_descriptions.items():\n",
    "    words = Counter(description)\n",
    "    for w, c in words.items():\n",
    "        i.append(movie_to_id[title])\n",
    "        j.append(vocab[w])\n",
    "        k.append(c)\n",
    "Matrix = scipy.sparse.csc_matrix((k, (i, j)), dtype=\"float32\")\n",
    "print(Matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, d, Vh = scipy.sparse.linalg.svds(Matrix, k=40, )\n",
    "U /= numpy.sqrt((U**2).sum(1))[:, None]\n",
    "Vh /= numpy.sqrt((Vh**2).sum(0))[None, :]\n",
    "print(U.shape)\n",
    "print(Vh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closests(v, k=1):\n",
    "    return numpy.argpartition(((U - v[None, :])**2).sum(1), k, axis=0)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closests(numpy.ones(len(Vh)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can search similar movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([id_to_movie[i] for i in closests(U[movie_to_id[b\"Monsters, Inc.\"]], 5)])\n",
    "print([id_to_movie[i] for i in closests(U[movie_to_id[b\"Popeye\"]], 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even mixture of movies by adding _\"movie vectors\"_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[id_to_movie[i] for i in closests(U[movie_to_id[b\"Popeye\"]] + U[movie_to_id[b\"Monsters, Inc.\"]], 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
